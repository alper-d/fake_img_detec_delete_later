{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from utils import videos_to_frames, extract_faces, interpolate_missing_frames, resize_excess, pad_resize, save_as_tensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FakeNet\n",
    "model = FakeNet()\n",
    "model = torch.nn.DataParallel(model)\n",
    "print(model)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_name = os.path.join('fake_class2_29_checkpoint.pth.tar')\n",
    "loaded_model = torch.load(load_name, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(loaded_model['state_dict'])\n",
    "#optimizer.load_state_dict(loaded_model['optimizer'])\n",
    "start_epoch = loaded_model['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run following lines to test on full data\n",
    "If you don't want please skip, datasize is approximately 4GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env KAGGLE_USERNAME=\"\"\n",
    "%env KAGGLE_KEY=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c deepfake-detection-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip deepfake-detection-challenge.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"deepfake-detection-challenge\", \"train_sample_videos\", \"metadata.json\"), 'r') as j:\n",
    "    metadata = j.read()\n",
    "\n",
    "filedata = metadata.replace('\"REAL\"', '1')\n",
    "filedata = filedata.replace('\"FAKE\"', '0')\n",
    "\n",
    "with open(os.path.join(\"deepfake-detection-challenge\", \"train_sample_videos\", \"metadata_edited.json\"), 'w') as file:\n",
    "  file.write(filedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following lines preprocess the data\n",
    "- demo_data_path should be the name of folder which encloses videos\n",
    "- If you want to preprocess videos and just want to use .pt tensors skip this section.\n",
    "- At the end of this section you should have .pt tensors saved inside the demo_data_path variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data_path = \"demo_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "videos_to_frames(demo_data_path)\n",
    "extract_faces(demo_data_path)\n",
    "interpolate_missing_frames(demo_data_path)\n",
    "resize_excess(demo_data_path)\n",
    "pad_resize(demo_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_tensor(demo_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable should be the path which encloses the .pt tensor\n",
    "demo_data_path = \"demo_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import FakeDetectDataset\n",
    "dataset = FakeDetectDataset(demo_data_path)\n",
    "data_loader_params = {'dataset': dataset, 'batch_size': 1, 'shuffle': False, 'sampler': None,\n",
    "                        'batch_sampler': None, 'num_workers': 0, 'collate_fn': None}\n",
    "eval_loader = DataLoader(**data_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    acc = 0\n",
    "    for (batch_no, sample) in enumerate(eval_loader):\n",
    "        inp = sample[0]\n",
    "        label = torch.tensor(sample[1], dtype=torch.float)\n",
    "        output = model(inp)\n",
    "        output = output.squeeze()\n",
    "        number_to_probs = lambda class_int: \"REAL prob: {:.2f} FAKE probability: {:.2f}\".format(torch.sigmoid(output), 1-torch.sigmoid(output).item()) \n",
    "        number_to_class = lambda class_int: \"REAL\" if  class_int > 0.5 else \"FAKE\"\n",
    "        print(output)\n",
    "        class_pred_prob = torch.sigmoid(output)\n",
    "        class_pred = 1 if class_pred_prob.item() > 0.5 else 0\n",
    "        if class_pred == label.item():\n",
    "            acc += 1\n",
    "        print(f\"Prediction = \\n\\t{number_to_probs(class_pred_prob.item())}\")\n",
    "        print(f\"Actual = \\n\\t{number_to_class(label.item())}\")\n",
    "    print(\"Accuracy is \" + str( acc / (batch_no +1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".3dvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
